{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConllEditor:\n",
    "    def __init__(self, file_path, encoding='utf-8'):\n",
    "        self.file_path = file_path\n",
    "        self.encoding = encoding\n",
    "        try:\n",
    "            self.data = self._load_data()\n",
    "        except UnicodeDecodeError:\n",
    "            # If UTF-8 fails, try with different encodings\n",
    "            encodings_to_try = ['latin1', 'iso-8859-1', 'cp1252']\n",
    "            for enc in encodings_to_try:\n",
    "                try:\n",
    "                    self.encoding = enc\n",
    "                    self.data = self._load_data()\n",
    "                    print(f\"Successfully loaded file using {enc} encoding\")\n",
    "                    break\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "            else:\n",
    "                raise UnicodeDecodeError(f\"Could not read file with any of these encodings: utf-8, {', '.join(encodings_to_try)}\")\n",
    "\n",
    "    def _load_data(self):\n",
    "        with open(self.file_path, 'r', encoding=self.encoding) as f:\n",
    "            lines = f.readlines()\n",
    "        return [line.strip() for line in lines]\n",
    "\n",
    "    def view_annotations(self):\n",
    "        annotations = [line for line in self.data if line and not line.startswith(\"-DOCSTART-\")]\n",
    "        annotation_count = len(annotations)\n",
    "        for annotation in annotations:\n",
    "            print(annotation)\n",
    "        print(f\"\\nTotal number of tokens: {annotation_count}\")\n",
    "    \n",
    "    def label_stats(self):\n",
    "        label_counter = Counter()\n",
    "        total_labels = 0\n",
    "        \n",
    "        for line in self.data:\n",
    "            if line and not line.startswith(\"-DOCSTART-\"):\n",
    "                label = line.split()[-1]\n",
    "                label_counter[label] += 1\n",
    "                total_labels += 1\n",
    "\n",
    "        unique_labels = len(label_counter)\n",
    "        \n",
    "        # Custom sorting function\n",
    "        def sort_key(label):\n",
    "            if label == 'O':\n",
    "                return ('0', '')  # Make 'O' come first\n",
    "            prefix = label[:2]  # B- or I-\n",
    "            entity = label[2:]  # The entity type after B- or I-\n",
    "            return (entity, prefix)  # Sort by entity type first, then B/I prefix\n",
    "        \n",
    "        # Sort and print labels\n",
    "        sorted_labels = sorted(label_counter.items(), key=lambda x: sort_key(x[0]))\n",
    "        for label, count in sorted_labels:\n",
    "            print(f\"Label: {label}, Count: {count}\")\n",
    "        \n",
    "        print(f\"\\nTotal number of labels found: {total_labels}\")\n",
    "        print(f\"Total number of unique tags: {unique_labels}\")\n",
    "\n",
    "    \n",
    "    def search_by_label(self, label):\n",
    "        matches = [(index, line) for index, line in enumerate(self.data) if line and not line.startswith(\"-DOCSTART-\") and line.endswith(label)]\n",
    "        token_count = len(matches)\n",
    "        \n",
    "        # Count sentences containing the label\n",
    "        sentence_count = 0\n",
    "        current_sentence_has_label = False\n",
    "\n",
    "        for line in self.data:\n",
    "            if not line:  # Empty line indicates end of sentence\n",
    "                if current_sentence_has_label:\n",
    "                    sentence_count += 1\n",
    "                current_sentence_has_label = False\n",
    "            elif line.endswith(label):\n",
    "                current_sentence_has_label = True\n",
    "\n",
    "        # Check the last sentence if it doesn't end with an empty line\n",
    "        if current_sentence_has_label:\n",
    "            sentence_count += 1\n",
    "\n",
    "        # Print matches with line numbers\n",
    "        for index, match in matches:\n",
    "            print(f\"Line {index + 1}: {match}\")\n",
    "\n",
    "        print(f\"\\nNumber of tokens found with label '{label}': {token_count}\")\n",
    "        print(f\"Number of sentences containing label '{label}': {sentence_count}\")\n",
    "\n",
    "    def search_by_token(self, token):\n",
    "        matches = [(index, line) for index, line in enumerate(self.data) if line and not line.startswith(\"-DOCSTART-\") and token in line]\n",
    "        token_count = len(matches)\n",
    "\n",
    "        # Count sentences containing the token\n",
    "        sentence_count = 0\n",
    "        current_sentence_has_token = False\n",
    "\n",
    "        for line in self.data:\n",
    "            if not line:  # Empty line indicates end of sentence\n",
    "                if current_sentence_has_token:\n",
    "                    sentence_count += 1\n",
    "                current_sentence_has_token = False\n",
    "            elif token in line:\n",
    "                current_sentence_has_token = True\n",
    "\n",
    "        # Check the last sentence if it doesn't end with an empty line\n",
    "        if current_sentence_has_token:\n",
    "            sentence_count += 1\n",
    "\n",
    "        # Print matches with line numbers\n",
    "        for index, match in matches:\n",
    "            print(f\"Line {index + 1}: {match}\")\n",
    "\n",
    "        print(f\"\\nNumber of tokens found with '{token}': {token_count}\")\n",
    "        print(f\"Number of sentences containing '{token}': {sentence_count}\")\n",
    "\n",
    "    def remove_label(self, label_to_remove):\n",
    "        new_data = []\n",
    "        for line in self.data:\n",
    "            if line.endswith(label_to_remove):\n",
    "                new_data.append(re.sub(rf\"\\s{label_to_remove}$\", \" O\", line))\n",
    "            else:\n",
    "                new_data.append(line)\n",
    "        self.data = new_data\n",
    "        print(f\"Label '{label_to_remove}' removed.\")\n",
    "    \n",
    "    def merge_labels(self, labels_to_merge, new_label):\n",
    "        new_data = []\n",
    "        for line in self.data:\n",
    "            if any(line.endswith(label) for label in labels_to_merge):\n",
    "                new_data.append(re.sub(rf\"\\s({'|'.join(labels_to_merge)})$\", f\" {new_label}\", line))\n",
    "            else:\n",
    "                new_data.append(line)\n",
    "        self.data = new_data\n",
    "        print(f\"Labels {labels_to_merge} merged into '{new_label}'.\")\n",
    "    \n",
    "    def rename_labels(self, label_mapping):\n",
    "        new_data = []\n",
    "        for line in self.data:\n",
    "            if line and not line.startswith(\"-DOCSTART-\"):\n",
    "                parts = line.split()\n",
    "                if parts:\n",
    "                    label = parts[-1]\n",
    "                    if label in label_mapping:\n",
    "                        parts[-1] = label_mapping[label]\n",
    "                    new_data.append(\" \".join(parts))\n",
    "            else:\n",
    "                new_data.append(line)\n",
    "        self.data = new_data\n",
    "        print(f\"Labels renamed according to {label_mapping}.\")\n",
    "\n",
    "    def delete_sentences_with_label(self, label_to_delete):\n",
    "        new_data = []\n",
    "        current_sentence = []\n",
    "        sentence_to_delete = False\n",
    "        sentences_deleted = 0\n",
    "        tokens_deleted = 0\n",
    "\n",
    "        for line in self.data:\n",
    "            if line.startswith(\"-DOCSTART-\"):\n",
    "                new_data.append(line)\n",
    "                continue\n",
    "\n",
    "            if not line:\n",
    "                if current_sentence and not sentence_to_delete:\n",
    "                    new_data.extend(current_sentence)\n",
    "                    new_data.append(line)\n",
    "                else:\n",
    "                    if sentence_to_delete:\n",
    "                        sentences_deleted += 1\n",
    "                        tokens_deleted += len(current_sentence)\n",
    "                current_sentence = []\n",
    "                sentence_to_delete = False\n",
    "            else:\n",
    "                current_sentence.append(line)\n",
    "                if line.split()[-1] == label_to_delete:\n",
    "                    sentence_to_delete = True\n",
    "\n",
    "        # Handle the last sentence if it exists\n",
    "        if current_sentence:\n",
    "            if sentence_to_delete:\n",
    "                sentences_deleted += 1\n",
    "                tokens_deleted += len(current_sentence)\n",
    "            else:\n",
    "                new_data.extend(current_sentence)\n",
    "\n",
    "        self.data = new_data\n",
    "        print(f\"Sentences containing the label '{label_to_delete}' have been deleted.\")\n",
    "        print(f\"Number of sentences deleted: {sentences_deleted}\")\n",
    "        print(f\"Number of tokens deleted: {tokens_deleted}\")\n",
    "\n",
    "    def delete_sentences_without_annotations(self):\n",
    "        new_data = []\n",
    "        current_sentence = []\n",
    "        sentence_has_annotation = False\n",
    "        sentences_deleted = 0\n",
    "        tokens_deleted = 0\n",
    "\n",
    "        for line in self.data:\n",
    "            if line.startswith(\"-DOCSTART-\"):\n",
    "                new_data.append(line)\n",
    "                continue\n",
    "\n",
    "            if not line:\n",
    "                if current_sentence and sentence_has_annotation:\n",
    "                    new_data.extend(current_sentence)\n",
    "                    new_data.append(line)\n",
    "                else:\n",
    "                    if current_sentence:\n",
    "                        sentences_deleted += 1\n",
    "                        tokens_deleted += len(current_sentence)\n",
    "                current_sentence = []\n",
    "                sentence_has_annotation = False\n",
    "            else:\n",
    "                current_sentence.append(line)\n",
    "                if line.split()[-1] != \"O\":\n",
    "                    sentence_has_annotation = True\n",
    "\n",
    "        # Handle the last sentence if it exists\n",
    "        if current_sentence:\n",
    "            if sentence_has_annotation:\n",
    "                new_data.extend(current_sentence)\n",
    "            else:\n",
    "                sentences_deleted += 1\n",
    "                tokens_deleted += len(current_sentence)\n",
    "\n",
    "        self.data = new_data\n",
    "        print(f\"Sentences without annotations have been deleted successfully.\")\n",
    "        print(f\"Number of sentences deleted: {sentences_deleted}\")\n",
    "        print(f\"Number of tokens deleted: {tokens_deleted}\")\n",
    "\n",
    "    def save(self, output_path):\n",
    "        try:\n",
    "            with open(output_path, 'w', encoding=self.encoding) as f:\n",
    "                f.write(\"\\n\".join(self.data) + \"\\n\")\n",
    "            print(f\"Updated file saved to {output_path} using {self.encoding} encoding\")\n",
    "        except UnicodeEncodeError:\n",
    "            # If the original encoding fails, try UTF-8\n",
    "            try:\n",
    "                with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"\\n\".join(self.data) + \"\\n\")\n",
    "                print(f\"Updated file saved to {output_path} using utf-8 encoding\")\n",
    "            except UnicodeEncodeError as e:\n",
    "                raise UnicodeEncodeError(f\"Failed to save file with both {self.encoding} and utf-8 encodings: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the editor with the CoNLL file path\n",
    "editor = ConllEditor(r'c:\\Users\\Sakib Ahmed\\Downloads\\Projekt 5 Dez 04 2024.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leukozyten -X- _ B-BIOMARKER\n",
      "4.3-10.8 -X- _ B-REFERENCE\n",
      "G -X- _ B-UNIT\n",
      "/ -X- _ O\n",
      "l -X- _ B-VALUE\n",
      "8.18 -X- _ I-VALUE\n",
      "Erythrozyten -X- _ B-BIOMARKER\n",
      "3.8-5.2 -X- _ B-REFERENCE\n",
      "T -X- _ O\n",
      "/ -X- _ B-VALUE\n",
      "l -X- _ I-VALUE\n",
      "4.56 -X- _ I-VALUE\n",
      "Hämoglobin -X- _ B-BIOMARKER\n",
      "120-160 -X- _ B-REFERENCE\n",
      "g -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "l -X- _ I-UNIT\n",
      "139.0 -X- _ B-VALUE\n",
      "Hämatokrit -X- _ B-BIOMARKER\n",
      "0,35-0,47 -X- _ B-REFERENCE\n",
      "l -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "l -X- _ O\n",
      "0.412 -X- _ B-VALUE\n",
      "MCV -X- _ B-BIOMARKER\n",
      "80-95 -X- _ B-REFERENCE\n",
      "fl -X- _ B-UNIT\n",
      "90.4 -X- _ B-VALUE\n",
      "MCH -X- _ B-BIOMARKER\n",
      "27-32 -X- _ B-REFERENCE\n",
      "pg -X- _ B-UNIT\n",
      "30.5 -X- _ B-VALUE\n",
      "MCHC -X- _ B-BIOMARKER\n",
      "310-360 -X- _ B-REFERENCE\n",
      "g -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "l -X- _ I-UNIT\n",
      "337 -X- _ B-VALUE\n",
      "Thrombozyten -X- _ B-BIOMARKER\n",
      "150-450 -X- _ B-REFERENCE\n",
      "G -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "182 -X- _ B-VALUE\n",
      "Mittleres -X- _ B-BIOMARKER\n",
      "Plättchen -X- _ I-BIOMARKER\n",
      "Volumen -X- _ I-BIOMARKER\n",
      "6,4-9,7 -X- _ B-REFERENCE\n",
      "fl -X- _ B-UNIT\n",
      "11.1+ -X- _ B-VALUE\n",
      "RDW -X- _ B-BIOMARKER\n",
      "% -X- _ B-UNIT\n",
      "13.0 -X- _ B-VALUE\n",
      "Granulozyten -X- _ B-BIOMARKER\n",
      "50-70 -X- _ B-REFERENCE\n",
      "% -X- _ O\n",
      "47- -X- _ B-VALUE\n",
      "Wertkontrolliert -X- _ B-COMMENT\n",
      "Lymphozyten -X- _ B-BIOMARKER\n",
      "25-40 -X- _ B-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "44+ -X- _ B-VALUE\n",
      "Wertkontrolliert -X- _ B-COMMENT\n",
      "Eosinophile -X- _ B-BIOMARKER\n",
      "0-4 -X- _ B-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "2 -X- _ B-VALUE\n",
      "Basophile -X- _ B-BIOMARKER\n",
      "0-1 -X- _ B-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "0 -X- _ B-VALUE\n",
      "Monocyten -X- _ B-BIOMARKER\n",
      "2-8 -X- _ B-REFERENCE\n",
      "% -X- _ O\n",
      "6 -X- _ O\n",
      "Wertkontrolliert -X- _ B-COMMENT\n",
      "Gerinnung -X- _ B-BIOMARKER\n",
      "Quick -X- _ I-BIOMARKER\n",
      "70-130 -X- _ B-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "> -X- _ B-VALUE\n",
      "100 -X- _ I-VALUE\n",
      "INR -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Quick -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "0.85-1.15 -X- _ B-REFERENCE\n",
      "0.94 -X- _ B-VALUE\n",
      "PTT -X- _ B-BIOMARKER\n",
      "22,3-31,7 -X- _ B-REFERENCE\n",
      "sec -X- _ B-UNIT\n",
      "25.2 -X- _ B-VALUE\n",
      "Natrium -X- _ B-BIOMARKER\n",
      "132-154 -X- _ B-REFERENCE\n",
      "mmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "L -X- _ I-UNIT\n",
      "143 -X- _ B-VALUE\n",
      "Kalium -X- _ B-BIOMARKER\n",
      "3,5-5,4 -X- _ B-REFERENCE\n",
      "mmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "L -X- _ O\n",
      "4.63 -X- _ B-VALUE\n",
      "Harnstoff -X- _ B-BIOMARKER\n",
      "1.7-8.3 -X- _ B-REFERENCE\n",
      "mmol -X- _ B-UNIT\n",
      "/ -X- _ O\n",
      "L -X- _ B-VALUE\n",
      "7.25 -X- _ I-VALUE\n",
      "Creatinin -X- _ B-BIOMARKER\n",
      "45-84 -X- _ B-REFERENCE\n",
      "umol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "l -X- _ O\n",
      "66 -X- _ B-VALUE\n",
      "Harnsäure -X- _ B-BIOMARKER\n",
      "140-340 -X- _ B-REFERENCE\n",
      "umol -X- _ B-UNIT\n",
      "/ -X- _ O\n",
      "l -X- _ B-VALUE\n",
      "241 -X- _ I-VALUE\n",
      "Bilirubingesamt -X- _ B-BIOMARKER\n",
      "0-17 -X- _ B-REFERENCE\n",
      "umol -X- _ B-UNIT\n",
      "/ -X- _ O\n",
      "l -X- _ B-VALUE\n",
      "4.3 -X- _ I-VALUE\n",
      "Protein -X- _ B-BIOMARKER\n",
      "66-87 -X- _ B-REFERENCE\n",
      "g -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "l -X- _ I-UNIT\n",
      "61.6- -X- _ B-VALUE\n",
      "Glucose -X- _ B-BIOMARKER\n",
      "3.9-5.5 -X- _ B-REFERENCE\n",
      "mmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "L -X- _ O\n",
      "4.70 -X- _ B-VALUE\n",
      "Calcium -X- _ B-BIOMARKER\n",
      "2.1-2.6 -X- _ B-REFERENCE\n",
      "mmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "L -X- _ O\n",
      "2.30 -X- _ B-VALUE\n",
      "GlomuläreFiltrationsrate -X- _ B-BIOMARKER\n",
      "95-110 -X- _ B-REFERENCE\n",
      "ml -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "min -X- _ I-UNIT\n",
      "86- -X- _ B-VALUE\n",
      "GOT -X- _ B-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "AST -X- _ I-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "33 -X- _ I-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "I -X- _ I-UNIT\n",
      "20 -X- _ B-VALUE\n",
      "ALT -X- _ B-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "GPT -X- _ I-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "35 -X- _ I-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "I -X- _ I-UNIT\n",
      "24 -X- _ B-VALUE\n",
      "AlkalischePhosphatase -X- _ B-BIOMARKER\n",
      "64-300 -X- _ B-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "103 -X- _ B-VALUE\n",
      "Gamma-GT -X- _ B-BIOMARKER\n",
      "0-38 -X- _ B-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "I -X- _ I-UNIT\n",
      "29 -X- _ B-VALUE\n",
      "LDH -X- _ B-BIOMARKER\n",
      "120-248 -X- _ B-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "I -X- _ O\n",
      "165 -X- _ B-VALUE\n",
      "Amylase -X- _ B-BIOMARKER\n",
      "27-100 -X- _ B-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "I -X- _ I-UNIT\n",
      "74 -X- _ B-VALUE\n",
      "Creatinkinase -X- _ B-BIOMARKER\n",
      "-145 -X- _ B-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "I -X- _ I-UNIT\n",
      "49 -X- _ B-VALUE\n",
      "BSG2 -X- _ B-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "h -X- _ I-BIOMARKER\n",
      "mm -X- _ B-UNIT\n",
      "25.0 -X- _ B-VALUE\n",
      "BSG1 -X- _ B-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "h -X- _ I-BIOMARKER\n",
      "mm -X- _ B-UNIT\n",
      "16.0 -X- _ B-VALUE\n",
      "TroponinI -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "0,026 -X- _ I-REFERENCE\n",
      "ng -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "ml -X- _ I-UNIT\n",
      "0.001 -X- _ B-VALUE\n",
      "C-reaktives-Protein -X- _ B-BIOMARKER\n",
      "-6.0 -X- _ B-REFERENCE\n",
      "mg -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "L -X- _ I-UNIT\n",
      "6.19+ -X- _ B-VALUE\n",
      "TSHbasal -X- _ B-BIOMARKER\n",
      "0,2-3,4 -X- _ B-REFERENCE\n",
      "mU -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "I -X- _ O\n",
      "3.325 -X- _ B-VALUE\n",
      "pH -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "T -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "7.35-7.45 -X- _ I-BIOMARKER\n",
      "7.41 -X- _ B-VALUE\n",
      "pO2 -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "T -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "83-108 -X- _ I-BIOMARKER\n",
      "mmHg -X- _ B-REFERENCE\n",
      "89.1 -X- _ B-UNIT\n",
      "pCO2 -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "T -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "32-45 -X- _ I-BIOMARKER\n",
      "mmHg -X- _ B-REFERENCE\n",
      "34.7 -X- _ B-UNIT\n",
      "Bicarbonat -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "21-26 -X- _ I-BIOMARKER\n",
      "mmol -X- _ B-REFERENCE\n",
      "/ -X- _ B-UNIT\n",
      "l -X- _ I-UNIT\n",
      "22.8 -X- _ I-UNIT\n",
      "Std.Basenüberschuß -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "-2-+3 -X- _ I-BIOMARKER\n",
      "mmol -X- _ B-REFERENCE\n",
      "/ -X- _ O\n",
      "l -X- _ B-UNIT\n",
      "-2.404 -X- _ I-UNIT\n",
      "O2-Sättigung -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "95-99 -X- _ I-BIOMARKER\n",
      "% -X- _ B-REFERENCE\n",
      "99.41 -X- _ I-REFERENCE\n",
      "TotalO2 -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "mmol -X- _ I-BIOMARKER\n",
      "/ -X- _ B-UNIT\n",
      "l -X- _ I-UNIT\n",
      "8.7 -X- _ I-UNIT\n",
      "O2-Einatem-Fraktion -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "% -X- _ O\n",
      "21.0 -X- _ B-VALUE\n",
      "COHb -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "0.5-1.5 -X- _ I-BIOMARKER\n",
      "% -X- _ B-REFERENCE\n",
      "4.61 -X- _ B-UNIT\n",
      "MetHb -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "0-1.5 -X- _ I-BIOMARKER\n",
      "% -X- _ B-REFERENCE\n",
      "0 -X- _ O\n",
      "Abnahme -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "kapillär -X- _ I-BIOMARKER\n",
      "Hämoglobin -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "12.0-16.0 -X- _ I-BIOMARKER\n",
      "g -X- _ B-REFERENCE\n",
      "/ -X- _ O\n",
      "dl -X- _ B-UNIT\n",
      "14.5 -X- _ I-UNIT\n",
      "MetHb -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "0-1.5 -X- _ I-BIOMARKER\n",
      "% -X- _ B-REFERENCE\n",
      "0 -X- _ O\n",
      "Hämoglobin -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Radiometer -X- _ I-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "POCT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "12.0-16.0 -X- _ I-BIOMARKER\n",
      "g -X- _ B-REFERENCE\n",
      "/ -X- _ O\n",
      "dl -X- _ B-UNIT\n",
      "14.5 -X- _ I-UNIT\n",
      "Leukozyten -X- _ B-BIOMARKER\n",
      "4x3-10.0 -X- _ B-REFERENCE\n",
      "10^3 -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "1 -X- _ O\n",
      "4.80 -X- _ B-VALUE\n",
      "Erythrozyten -X- _ B-BIOMARKER\n",
      "4.10-5.10 -X- _ B-REFERENCE\n",
      "10~6 -X- _ B-UNIT\n",
      "/ -X- _ O\n",
      "H -X- _ O\n",
      "Hamoglobin -X- _ B-BIOMARKER\n",
      "12.3-15.3 -X- _ B-REFERENCE\n",
      "12.7 -X- _ B-VALUE\n",
      "Hamatokrit -X- _ B-BIOMARKER\n",
      "33.5-43.1 -X- _ B-REFERENCE\n",
      "36.8 -X- _ B-VALUE\n",
      "MCV -X- _ B-BIOMARKER\n",
      "77.0-96.0 -X- _ B-REFERENCE\n",
      "94.3 -X- _ B-VALUE\n",
      "MCH -X- _ B-BIOMARKER\n",
      "26.0-33.0 -X- _ B-REFERENCE\n",
      "pg -X- _ B-UNIT\n",
      "32.5 -X- _ B-VALUE\n",
      "MCHC -X- _ B-BIOMARKER\n",
      "33.0-35.0 -X- _ B-REFERENCE\n",
      "g -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "dl -X- _ I-UNIT\n",
      "34.5 -X- _ B-VALUE\n",
      "Thrombozyten -X- _ B-BIOMARKER\n",
      "150-400 -X- _ B-REFERENCE\n",
      "273 -X- _ B-VALUE\n",
      "Quick -X- _ B-BIOMARKER\n",
      "70-130 -X- _ B-REFERENCE\n",
      "de -X- _ B-UNIT\n",
      "109 -X- _ B-VALUE\n",
      "INR -X- _ B-BIOMARKER\n",
      "0.70-1.30 -X- _ B-REFERENCE\n",
      "0.94 -X- _ B-VALUE\n",
      "Natrium -X- _ B-BIOMARKER\n",
      "135-145 -X- _ B-REFERENCE\n",
      "mmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "1 -X- _ I-UNIT\n",
      "140 -X- _ B-VALUE\n",
      "Kalium -X- _ B-BIOMARKER\n",
      "3.5-5.1 -X- _ B-REFERENCE\n",
      "mmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "1 -X- _ I-UNIT\n",
      "4.0 -X- _ B-VALUE\n",
      "Magnesium -X- _ B-BIOMARKER\n",
      "0.75~1.1 -X- _ B-REFERENCE\n",
      "mmo1 -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "1 -X- _ I-UNIT\n",
      "0.84 -X- _ B-VALUE\n",
      "Harnstoff -X- _ B-BIOMARKER\n",
      "17-48 -X- _ B-REFERENCE\n",
      "mg -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "dl -X- _ I-UNIT\n",
      "17 -X- _ B-VALUE\n",
      "Kreatinin -X- _ B-BIOMARKER\n",
      "0.5-1.0 -X- _ B-REFERENCE\n",
      "mgrul -X- _ B-UNIT\n",
      "0.58 -X- _ B-VALUE\n",
      "CKD-EPI -X- _ B-BIOMARKER\n",
      "> -X- _ B-REFERENCE\n",
      "90 -X- _ I-REFERENCE\n",
      "ml -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "min -X- _ I-UNIT\n",
      "> -X- _ O\n",
      "90 -X- _ B-VALUE\n",
      "Bilirubingesamt -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "1.2 -X- _ I-REFERENCE\n",
      "mg -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "dl -X- _ I-UNIT\n",
      "0.4 -X- _ B-VALUE\n",
      "GOT -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "ASAT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "35 -X- _ I-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "1 -X- _ I-UNIT\n",
      "20 -X- _ B-VALUE\n",
      "GPT -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "ALAT -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "35 -X- _ I-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "1 -X- _ I-UNIT\n",
      "20 -X- _ B-VALUE\n",
      "LEGT -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "RO -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "40 -X- _ I-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "1 -X- _ I-UNIT\n",
      "9 -X- _ B-VALUE\n",
      "AlkalischePhosphatase -X- _ B-BIOMARKER\n",
      "35-105 -X- _ B-REFERENCE\n",
      "0 -X- _ I-REFERENCE\n",
      "/ -X- _ O\n",
      "1 -X- _ B-UNIT\n",
      "43 -X- _ I-UNIT\n",
      "Cholesterin -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "200 -X- _ I-REFERENCE\n",
      "mg -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "dl -X- _ I-UNIT\n",
      "95 -X- _ B-VALUE\n",
      "HDL-Cholesterin -X- _ B-BIOMARKER\n",
      "> -X- _ B-REFERENCE\n",
      "45 -X- _ I-REFERENCE\n",
      "mg -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "dl -X- _ I-UNIT\n",
      "77 -X- _ B-VALUE\n",
      "LDL-Cholesterin -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "direkt -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "2160 -X- _ B-VALUE\n",
      "Chol -X- _ B-BIOMARKER\n",
      "/ -X- _ I-BIOMARKER\n",
      "HDL-Quotient -X- _ I-BIOMARKER\n",
      "1.0-3.4 -X- _ B-REFERENCE\n",
      "2.5 -X- _ B-VALUE\n",
      "Triglyceride -X- _ B-BIOMARKER\n",
      "mg -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "dl -X- _ I-UNIT\n",
      "87 -X- _ B-VALUE\n",
      "CK -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "170 -X- _ I-REFERENCE\n",
      "49 -X- _ B-VALUE\n",
      "TSHbasal -X- _ B-BIOMARKER\n",
      "0.27-4.2 -X- _ B-REFERENCE\n",
      "mu -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "1 -X- _ I-UNIT\n",
      "1.42 -X- _ B-VALUE\n",
      "VitaminB12 -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "ECLIA -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "197-771 -X- _ B-REFERENCE\n",
      "pg -X- _ I-REFERENCE\n",
      "/ -X- _ O\n",
      "ml -X- _ B-UNIT\n",
      "730 -X- _ I-UNIT\n",
      "HbAlc -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "IFCC -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Elpho -X- _ I-BIOMARKER\n",
      ") -X- _ O\n",
      "nmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "m -X- _ I-UNIT\n",
      "27.0 -X- _ B-VALUE\n",
      "Glukose -X- _ B-BIOMARKER\n",
      "60-100 -X- _ B-REFERENCE\n",
      "mg -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "dl -X- _ I-UNIT\n",
      "84 -X- _ B-VALUE\n",
      "spez.GewichtST -X- _ B-BIOMARKER\n",
      "1.015-1.025 -X- _ B-REFERENCE\n",
      "g -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "ml -X- _ I-UNIT\n",
      "1.020 -X- _ B-VALUE\n",
      "PH-WertST -X- _ B-BIOMARKER\n",
      "5.0-8.0 -X- _ B-REFERENCE\n",
      "5.0 -X- _ B-VALUE\n",
      "BioenergetischerGesundheitsindex -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "BHI -X- _ I-BIOMARKER\n",
      ") -X- _ B-REFERENCE\n",
      "> -X- _ I-REFERENCE\n",
      "2.00 -X- _ I-REFERENCE\n",
      "1.51 -X- _ B-VALUE\n",
      "BioenergetischerGesundheitsindex -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "BHI -X- _ I-BIOMARKER\n",
      ") -X- _ B-REFERENCE\n",
      "> -X- _ I-REFERENCE\n",
      "2.00 -X- _ I-REFERENCE\n",
      "1.51 -X- _ B-VALUE\n",
      "BasaleAtmung -X- _ B-BIOMARKER\n",
      "pmol02 -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "min -X- _ I-UNIT\n",
      "16.49 -X- _ B-VALUE\n",
      "Protonenleck -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "9.00 -X- _ I-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "13.37 -X- _ B-VALUE\n",
      "MaximalerSauerstoffverbrauch -X- _ B-BIOMARKER\n",
      "> -X- _ B-REFERENCE\n",
      "450 -X- _ I-REFERENCE\n",
      "% -X- _ B-VALUE\n",
      "311.09 -X- _ I-VALUE\n",
      "ATP-Produktion -X- _ B-BIOMARKER\n",
      "> -X- _ B-REFERENCE\n",
      "91.00 -X- _ I-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "86.63 -X- _ B-VALUE\n",
      "Reserveatmungskapazität -X- _ B-BIOMARKER\n",
      "> -X- _ O\n",
      "350 -X- _ B-REFERENCE\n",
      "211.09 -X- _ B-VALUE\n",
      "Nicht-mitochondrialeAtmung -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "8.00 -X- _ I-REFERENCE\n",
      "pmol02 -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "min -X- _ I-UNIT\n",
      "6.75 -X- _ B-VALUE\n",
      "MitochondrialeAtmung -X- _ B-BIOMARKER\n",
      "> -X- _ O\n",
      "59 -X- _ B-REFERENCE\n",
      "% -X- _ O\n",
      "46 -X- _ B-VALUE\n",
      "Nicht-mitochondrialeAtmung -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "32 -X- _ I-REFERENCE\n",
      "% -X- _ O\n",
      "41 -X- _ B-VALUE\n",
      "ATP-Umsatz -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "22 -X- _ I-REFERENCE\n",
      "% -X- _ O\n",
      "33 -X- _ B-VALUE\n",
      "ATP-Reserve -X- _ B-BIOMARKER\n",
      "> -X- _ B-REFERENCE\n",
      "78 -X- _ I-REFERENCE\n",
      "% -X- _ O\n",
      "67 -X- _ B-VALUE\n",
      "Rhodanase -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "0.01 -X- _ I-REFERENCE\n",
      "0.00 -X- _ B-VALUE\n",
      "VitaminD3 -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "1,25OH -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "48-192 -X- _ B-REFERENCE\n",
      "pmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "l -X- _ I-UNIT\n",
      "164 -X- _ B-VALUE\n",
      "VitaminD3 -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "25OH -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "62.5-170 -X- _ B-REFERENCE\n",
      "nmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "l -X- _ I-UNIT\n",
      "89.20 -X- _ B-VALUE\n",
      "Vitamin-D-Ratio -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "1.0 -X- _ I-REFERENCE\n",
      "pmol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "nmol -X- _ I-UNIT\n",
      "1.84 -X- _ B-VALUE\n",
      "IL-6 -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "15,0 -X- _ I-REFERENCE\n",
      "pg -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "ml -X- _ I-UNIT\n",
      "8.9 -X- _ B-VALUE\n",
      "IL-8 -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "15,0 -X- _ I-REFERENCE\n",
      "pg -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "m -X- _ I-UNIT\n",
      "6.5 -X- _ B-VALUE\n",
      "Neopterin -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "2,5 -X- _ I-REFERENCE\n",
      "ng -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "m -X- _ I-UNIT\n",
      "2,7 -X- _ B-VALUE\n",
      "ImmunkompetenzViren -X- _ B-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "TH1Elispot -X- _ I-BIOMARKER\n",
      ") -X- _ O\n",
      "> -X- _ B-REFERENCE\n",
      "25 -X- _ I-REFERENCE\n",
      "Spot -X- _ B-UNIT\n",
      "17,00 -X- _ B-VALUE\n",
      "StimulationsindexVirenpool -X- _ B-BIOMARKER\n",
      "Index -X- _ B-UNIT\n",
      "18,0 -X- _ B-VALUE\n",
      "LP-PLA2 -X- _ B-BIOMARKER\n",
      ":507 -X- _ B-REFERENCE\n",
      "U -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "I -X- _ I-UNIT\n",
      "347 -X- _ B-VALUE\n",
      "oxidiertesLDL -X- _ B-BIOMARKER\n",
      "< -X- _ O\n",
      "133,2 -X- _ B-REFERENCE\n",
      "ng -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "m -X- _ I-UNIT\n",
      "< -X- _ O\n",
      "41,30 -X- _ B-VALUE\n",
      "Lipidperoxidation -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "200 -X- _ I-REFERENCE\n",
      "umol -X- _ B-UNIT\n",
      "212,00 -X- _ B-VALUE\n",
      "L-Carnitingesamt -X- _ B-BIOMARKER\n",
      "39,1-68,6 -X- _ B-REFERENCE\n",
      "umol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "l -X- _ I-UNIT\n",
      "44,50 -X- _ B-VALUE\n",
      "L-Carnitinfrei -X- _ B-BIOMARKER\n",
      "30,4-52,9 -X- _ B-REFERENCE\n",
      "umol -X- _ B-UNIT\n",
      "/ -X- _ I-UNIT\n",
      "l -X- _ I-UNIT\n",
      "32.50 -X- _ B-VALUE\n",
      "L-Carnitin -X- _ B-BIOMARKER\n",
      ", -X- _ I-BIOMARKER\n",
      "verestert -X- _ I-BIOMARKER\n",
      "( -X- _ I-BIOMARKER\n",
      "Acylcarnitin -X- _ I-BIOMARKER\n",
      ") -X- _ I-BIOMARKER\n",
      "-30 -X- _ I-BIOMARKER\n",
      "umol -X- _ B-REFERENCE\n",
      "/ -X- _ B-UNIT\n",
      "l -X- _ I-UNIT\n",
      "12,00 -X- _ I-UNIT\n",
      "EBVakut -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "5 -X- _ I-REFERENCE\n",
      "SI -X- _ B-UNIT\n",
      "42,0 -X- _ B-VALUE\n",
      "EBVlatent -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "5 -X- _ I-REFERENCE\n",
      "S -X- _ B-UNIT\n",
      "22,0 -X- _ B-VALUE\n",
      "VCAp18 -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "15 -X- _ I-REFERENCE\n",
      "143 -X- _ B-VALUE\n",
      "VCAp23 -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "15 -X- _ I-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "38 -X- _ B-VALUE\n",
      "EBNA1IgG -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "15 -X- _ I-REFERENCE\n",
      "32 -X- _ B-VALUE\n",
      "EAp54 -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "15 -X- _ I-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "55 -X- _ B-VALUE\n",
      "EAp138 -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "15 -X- _ I-REFERENCE\n",
      "10 -X- _ B-VALUE\n",
      "Zebra -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "15 -X- _ I-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "6 -X- _ B-VALUE\n",
      "VCAp18 -X- _ B-BIOMARKER\n",
      "< -X- _ B-REFERENCE\n",
      "15 -X- _ I-REFERENCE\n",
      "% -X- _ B-UNIT\n",
      "5 -X- _ B-VALUE\n",
      "VCAp23 -X- _ B-BIOMARKER\n",
      "≤15 -X- _ B-REFERENCE\n",
      "≤15 -X- _ B-VALUE\n",
      "\n",
      "Total number of tokens: 773\n"
     ]
    }
   ],
   "source": [
    "# 1. View Annotations\n",
    "editor.view_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: O, Count: 37\n",
      "Label: B-BIOMARKER, Count: 124\n",
      "Label: I-BIOMARKER, Count: 146\n",
      "Label: B-COMMENT, Count: 3\n",
      "Label: B-REFERENCE, Count: 112\n",
      "Label: I-REFERENCE, Count: 41\n",
      "Label: B-UNIT, Count: 92\n",
      "Label: I-UNIT, Count: 103\n",
      "Label: B-VALUE, Count: 107\n",
      "Label: I-VALUE, Count: 8\n",
      "\n",
      "Total number of labels found: 773\n",
      "Total number of unique tags: 10\n"
     ]
    }
   ],
   "source": [
    "# 2. Label Statistics\n",
    "editor.label_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 3: Hulls -X- _ B-PER\n",
      "Line 188: Areces -X- _ B-PER\n",
      "Line 195: Juan -X- _ B-PER\n",
      "Line 442: Jaime -X- _ B-PER\n",
      "Line 446: Chevenement -X- _ B-PER\n",
      "Line 680: Luis -X- _ B-PER\n",
      "Line 749: Conchita -X- _ B-PER\n",
      "Line 764: Martina -X- _ B-PER\n",
      "Line 809: SuÃ¡rez -X- _ B-PER\n",
      "...\n",
      "Line 109121: Samani -X- _ B-PER\n",
      "\n",
      "Number of tokens found with label 'B-PER': 1669\n",
      "Number of sentences containing label 'B-PER': 1079\n"
     ]
    }
   ],
   "source": [
    "# 3. Search Annotations with a specific label\n",
    "editor.search_by_label('B-PER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 26203: Florida -X- _ B-LOC\n",
      "\n",
      "Number of tokens found with 'Florida': 1\n",
      "Number of sentences containing 'Florida': 1\n"
     ]
    }
   ],
   "source": [
    "# 4. Search Annotations with a specific label\n",
    "editor.search_by_token(\"Florida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 'B-PER' removed.\n"
     ]
    }
   ],
   "source": [
    "# 5. Remove specific label\n",
    "editor.remove_label('B-PER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels ['B-MISC', 'I-MISC', 'B-ORG'] merged into 'C-MISC'.\n"
     ]
    }
   ],
   "source": [
    "# 6. Merge multiple labels into one\n",
    "editor.merge_labels(['B-MISC', 'I-MISC', 'B-ORG'], 'C-MISC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: O, Count: 236241\n",
      "Label: C-MISC, Count: 12775\n",
      "Label: B-LOC, Count: 4913\n",
      "Label: I-ORG, Count: 4992\n",
      "Label: I-LOC, Count: 1891\n",
      "Label: I-PER, Count: 3903\n",
      "\n",
      "Total number of labels found: 264715\n"
     ]
    }
   ],
   "source": [
    "# Rechecking Label Statistics\n",
    "editor.label_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels renamed according to {'I-PER': 'A-MISC', 'B-LOC': 'A-LOC'}.\n"
     ]
    }
   ],
   "source": [
    "# 7. Rename labels based on JSON mapping\n",
    "editor.rename_labels({\n",
    "    'I-PER':'A-MISC',\n",
    "    'B-LOC':'A-LOC'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: O, Count: 236241\n",
      "Label: C-MISC, Count: 12775\n",
      "Label: A-LOC, Count: 4913\n",
      "Label: I-ORG, Count: 4992\n",
      "Label: I-LOC, Count: 1891\n",
      "Label: A-MISC, Count: 3903\n",
      "\n",
      "Total number of labels found: 264715\n"
     ]
    }
   ],
   "source": [
    "# Rechecking Label Statistics\n",
    "editor.label_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences containing the label 'I-LOC' have been deleted.\n",
      "Number of sentences deleted: 413\n",
      "Number of tokens deleted: 14029\n"
     ]
    }
   ],
   "source": [
    "# 8. Delete an entire sentence containing an specific label\n",
    "editor.delete_sentences_with_label(\"I-LOC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentences without annotations have been deleted successfully.\n",
      "Number of sentences deleted: 2123\n",
      "Number of tokens deleted: 31337\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "# 9. Delete an entire sentence containing no label\n",
    "editor.delete_sentences_without_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated file saved to updated_conll_file.conll\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "# Save the updated CoNLL file\n",
    "editor.save('updated_conll_file.conll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some additional scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-ASCII lines remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_lines_with_gaps(file_path):\n",
    "    cleaned_lines = []\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if line is either empty or contains only ASCII characters\n",
    "        if line.strip() == '' or re.match(r'^[\\x00-\\x7F]+$', line.strip()):\n",
    "            cleaned_lines.append(line)  # Keep the line\n",
    "\n",
    "    # Save cleaned lines to a new file\n",
    "    with open('output.conll', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(cleaned_lines)\n",
    "    \n",
    "    print(\"Non-ASCII tokens removed successfully\")\n",
    "\n",
    "# Use the path to your .conll file here\n",
    "clean_lines_with_gaps(r'updated_conll_file.conll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates Remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import glob\n",
    "from io import StringIO\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = './data'\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, 'removed_duplicates')\n",
    "ALLOWED_EXTENSIONS = {'conll'}\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def get_next_file_number():\n",
    "    existing_files = glob.glob(os.path.join(OUTPUT_DIR, 'cleaned_*.conll'))\n",
    "    if not existing_files:\n",
    "        return 1\n",
    "    numbers = [int(f.split('_')[-1].split('.')[0]) for f in existing_files]\n",
    "    return max(numbers) + 1\n",
    "\n",
    "def parse_conll_content(content):\n",
    "    \"\"\"Parse CoNLL content into sentences\"\"\"\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    \n",
    "    for line in content.split('\\n'):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Skip DOCSTART\n",
    "        if line.startswith('-DOCSTART-'):\n",
    "            continue\n",
    "            \n",
    "        if line:\n",
    "            current_sentence.append(line)\n",
    "        elif current_sentence:  # Empty line and we have a sentence\n",
    "            sentences.append('\\n'.join(current_sentence))\n",
    "            current_sentence = []\n",
    "            \n",
    "    # Add last sentence if exists\n",
    "    if current_sentence:\n",
    "        sentences.append('\\n'.join(current_sentence))\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "def remove_duplicates(content):\n",
    "    \"\"\"Remove duplicate sentences and track removed ones\"\"\"\n",
    "    # Initialize output buffers\n",
    "    cleaned_output = StringIO()\n",
    "    removed_output = StringIO()\n",
    "    \n",
    "    # Add headers\n",
    "    cleaned_output.write('-DOCSTART- -X- O O\\n\\n')\n",
    "    removed_output.write('-DOCSTART- -X- O O\\n\\n')\n",
    "    \n",
    "    # Parse into sentences\n",
    "    sentences = parse_conll_content(content)\n",
    "    \n",
    "    # Track unique and duplicate sentences\n",
    "    seen_sentences = {}  # Hash -> First occurrence index\n",
    "    unique_sentences = []\n",
    "    removed_sentences = []\n",
    "    \n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        # Create hash of the sentence\n",
    "        sentence_hash = hashlib.md5(sentence.encode()).hexdigest()\n",
    "        \n",
    "        if sentence_hash not in seen_sentences:\n",
    "            seen_sentences[sentence_hash] = idx\n",
    "            unique_sentences.append(sentence)\n",
    "        else:\n",
    "            # Store duplicate with its position information\n",
    "            original_pos = seen_sentences[sentence_hash] + 1  # 1-based indexing\n",
    "            current_pos = idx + 1\n",
    "            removed_sentences.append((sentence, original_pos, current_pos))\n",
    "    \n",
    "    # Write unique sentences to cleaned output\n",
    "    for sentence in unique_sentences:\n",
    "        cleaned_output.write(sentence + '\\n\\n')\n",
    "    \n",
    "    # Write removed sentences to removed output with position information\n",
    "    for sentence, original_pos, current_pos in removed_sentences:\n",
    "        removed_output.write(f\"# Duplicate of sentence #{original_pos}, found at position #{current_pos}\\n\")\n",
    "        removed_output.write(sentence + '\\n\\n')\n",
    "    \n",
    "    return (\n",
    "        cleaned_output.getvalue(),\n",
    "        removed_output.getvalue(),\n",
    "        len(sentences),\n",
    "        len(unique_sentences),\n",
    "        len(removed_sentences)\n",
    "    )\n",
    "\n",
    "def main(file_path):\n",
    "    if not allowed_file(file_path):\n",
    "        print('Invalid file type. Only .conll files are allowed')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Read the content\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Process the content\n",
    "        cleaned_content, removed_content, original_count, unique_count, removed_count = remove_duplicates(content)\n",
    "        \n",
    "        # Get next file number and create formatted number string\n",
    "        file_number = get_next_file_number()\n",
    "        formatted_number = f\"{file_number:04d}\"\n",
    "        \n",
    "        # Create output filenames\n",
    "        cleaned_filename = f\"cleaned_{formatted_number}.conll\"\n",
    "        removed_filename = f\"removed_sentences_{formatted_number}.conll\"\n",
    "        \n",
    "        # Create full paths\n",
    "        cleaned_path = os.path.join(OUTPUT_DIR, cleaned_filename)\n",
    "        removed_path = os.path.join(OUTPUT_DIR, removed_filename)\n",
    "        \n",
    "        # Save the files\n",
    "        with open(cleaned_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(cleaned_content)\n",
    "            \n",
    "        with open(removed_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(removed_content)\n",
    "        \n",
    "        # Print success message with file information\n",
    "        print(f'File deduplicated successfully:')\n",
    "        print(f'Cleaned file saved to: {cleaned_path}')\n",
    "        print(f'Removed sentences file saved to: {removed_path}')\n",
    "        print(f'Statistics:')\n",
    "        print(f'Original sentences: {original_count}')\n",
    "        print(f'Unique sentences: {unique_count}')\n",
    "        print(f'Duplicates removed: {removed_count}')\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        print('Invalid file encoding. File must be UTF-8 encoded')\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {str(e)}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Replace 'path/to/your_file.conll' with the actual file path\n",
    "    main(r'c:\\Users\\Sakib Ahmed\\Downloads\\project-20-at-2024-10-31-22-29-f2d4705b.conll')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
